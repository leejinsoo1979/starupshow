import { NextRequest, NextResponse } from 'next/server'
import OpenAI from 'openai'
import { getModelConfig, getApiModelId, SYSTEM_PROMPTS } from '@/lib/ai/models'
import { getToolsForProvider, AGENT_TOOLS } from '@/lib/ai/tools'
import { ToolExecutor, ToolResultWithAction } from '@/lib/ai/tool-executor'
import type { AgentAction } from '@/lib/ai/agent-actions'

export const dynamic = 'force-dynamic'
export const maxDuration = 60

interface ChatMessage {
  role: 'system' | 'user' | 'assistant' | 'tool'
  content: string
  tool_calls?: Array<{
    id: string
    type: 'function'
    function: { name: string; arguments: string }
  }>
  tool_call_id?: string
  name?: string
}

interface AgentContext {
  files: Array<{
    id: string
    name: string
    path?: string
    content?: string
    type: string
  }>
  projectPath?: string
  graph?: {
    title?: string
    nodes: Array<{
      id: string
      type: string
      title: string
      sourceRef?: { fileId: string }
    }>
  }
}

const MAX_ITERATIONS = 10

// ============================================
// Provider Handlers with Tools
// ============================================

async function runOpenAIAgent(
  messages: ChatMessage[],
  apiModel: string,
  tools: any[],
  executor: ToolExecutor,
  apiKey: string,
  baseURL?: string
): Promise<{ content: string; toolCalls: string[]; pendingActions: AgentAction[] }> {
  const client = new OpenAI({ apiKey, baseURL })
  const toolCallLog: string[] = []
  const pendingActions: AgentAction[] = []
  let currentMessages = [...messages]

  for (let i = 0; i < MAX_ITERATIONS; i++) {
    const completion = await client.chat.completions.create({
      model: apiModel,
      messages: currentMessages as any,
      tools: tools.length > 0 ? tools : undefined,
      tool_choice: tools.length > 0 ? 'auto' : undefined,
    })

    const assistantMessage = completion.choices[0]?.message
    if (!assistantMessage) break

    // ë„êµ¬ í˜¸ì¶œì´ ì—†ìœ¼ë©´ ìµœì¢… ì‘ë‹µ
    if (!assistantMessage.tool_calls || assistantMessage.tool_calls.length === 0) {
      return {
        content: assistantMessage.content || '',
        toolCalls: toolCallLog,
        pendingActions
      }
    }

    // ë„êµ¬ í˜¸ì¶œ ì²˜ë¦¬
    const toolCalls = assistantMessage.tool_calls as Array<{
      id: string
      type: 'function'
      function: { name: string; arguments: string }
    }>

    currentMessages.push({
      role: 'assistant',
      content: assistantMessage.content || '',
      tool_calls: assistantMessage.tool_calls as any
    })

    // ë³‘ë ¬ ë„êµ¬ í˜¸ì¶œ (Cursor ìŠ¤íƒ€ì¼ - Promise.all)
    const toolResults = await Promise.all(
      toolCalls.map(async (toolCall) => {
        const args = JSON.parse(toolCall.function.arguments)
        toolCallLog.push(`${toolCall.function.name}(${JSON.stringify(args)})`)

        const result: ToolResultWithAction = await executor.execute({
          name: toolCall.function.name,
          arguments: args
        })

        // ì•¡ì…˜ì´ ìˆìœ¼ë©´ ìˆ˜ì§‘
        if (result.pendingAction) {
          pendingActions.push(result.pendingAction)
        }

        return {
          role: 'tool' as const,
          content: JSON.stringify(result),
          tool_call_id: toolCall.id
        }
      })
    )

    // ê²°ê³¼ë¥¼ ë©”ì‹œì§€ì— ì¶”ê°€
    currentMessages.push(...toolResults)
  }

  return { content: 'ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.', toolCalls: toolCallLog, pendingActions }
}

async function runAnthropicAgent(
  messages: ChatMessage[],
  apiModel: string,
  tools: any[],
  executor: ToolExecutor,
  apiKey: string
): Promise<{ content: string; toolCalls: string[]; pendingActions: AgentAction[] }> {
  const toolCallLog: string[] = []
  const pendingActions: AgentAction[] = []

  // ì‹œìŠ¤í…œ ë©”ì‹œì§€ ë¶„ë¦¬
  const systemMessages = messages.filter(m => m.role === 'system')
  let currentMessages = messages.filter(m => m.role !== 'system')

  for (let i = 0; i < MAX_ITERATIONS; i++) {
    const response = await fetch('https://api.anthropic.com/v1/messages', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'x-api-key': apiKey,
        'anthropic-version': '2023-06-01',
      },
      body: JSON.stringify({
        model: apiModel,
        max_tokens: 4096,
        system: systemMessages.map(m => m.content).join('\n'),
        tools: tools.length > 0 ? tools : undefined,
        messages: currentMessages.map(m => ({
          role: m.role === 'tool' ? 'user' : m.role,
          content: m.role === 'tool'
            ? [{ type: 'tool_result', tool_use_id: m.tool_call_id, content: m.content }]
            : m.content
        }))
      })
    })

    if (!response.ok) {
      throw new Error(`Anthropic API Error: ${response.status}`)
    }

    const data = await response.json()
    const content = data.content || []

    // í…ìŠ¤íŠ¸ ì‘ë‹µ ì¶”ì¶œ
    const textParts = content.filter((c: any) => c.type === 'text')
    const toolUses = content.filter((c: any) => c.type === 'tool_use')

    // ë„êµ¬ í˜¸ì¶œì´ ì—†ìœ¼ë©´ ìµœì¢… ì‘ë‹µ
    if (toolUses.length === 0) {
      return {
        content: textParts.map((c: any) => c.text).join('\n'),
        toolCalls: toolCallLog,
        pendingActions
      }
    }

    // ë„êµ¬ í˜¸ì¶œ ì²˜ë¦¬ (ë³‘ë ¬)
    currentMessages.push({ role: 'assistant', content: JSON.stringify(content) })

    const toolResults = await Promise.all(
      toolUses.map(async (toolUse: any) => {
        toolCallLog.push(`${toolUse.name}(${JSON.stringify(toolUse.input)})`)

        const result: ToolResultWithAction = await executor.execute({
          name: toolUse.name,
          arguments: toolUse.input
        })

        // ì•¡ì…˜ì´ ìˆìœ¼ë©´ ìˆ˜ì§‘
        if (result.pendingAction) {
          pendingActions.push(result.pendingAction)
        }

        return {
          role: 'tool' as const,
          content: JSON.stringify(result),
          tool_call_id: toolUse.id
        }
      })
    )

    currentMessages.push(...toolResults)
  }

  return { content: 'ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.', toolCalls: toolCallLog, pendingActions }
}

async function runGoogleAgent(
  messages: ChatMessage[],
  apiModel: string,
  tools: any[],
  executor: ToolExecutor,
  apiKey: string
): Promise<{ content: string; toolCalls: string[]; pendingActions: AgentAction[] }> {
  const toolCallLog: string[] = []
  const pendingActions: AgentAction[] = []

  // ì‹œìŠ¤í…œ + ëŒ€í™” ë¶„ë¦¬
  const systemMessages = messages.filter(m => m.role === 'system')
  let chatMessages = messages.filter(m => m.role !== 'system')

  const systemInstruction = systemMessages.length > 0
    ? { parts: [{ text: systemMessages.map(m => m.content).join('\n') }] }
    : undefined

  for (let i = 0; i < MAX_ITERATIONS; i++) {
    const contents = chatMessages.map(m => ({
      role: m.role === 'assistant' ? 'model' : 'user',
      parts: [{ text: m.content }]
    }))

    const url = `https://generativelanguage.googleapis.com/v1beta/models/${apiModel}:generateContent?key=${apiKey}`

    const response = await fetch(url, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        systemInstruction,
        contents,
        tools: tools.length > 0 ? tools : undefined,
      })
    })

    if (!response.ok) {
      throw new Error(`Gemini API Error: ${response.status}`)
    }

    const data = await response.json()
    const parts = data.candidates?.[0]?.content?.parts || []

    // í•¨ìˆ˜ í˜¸ì¶œ í™•ì¸
    const functionCalls = parts.filter((p: any) => p.functionCall)
    const textParts = parts.filter((p: any) => p.text)

    if (functionCalls.length === 0) {
      return {
        content: textParts.map((p: any) => p.text).join('\n'),
        toolCalls: toolCallLog,
        pendingActions
      }
    }

    // í•¨ìˆ˜ í˜¸ì¶œ ì²˜ë¦¬ (ë³‘ë ¬)
    chatMessages.push({
      role: 'assistant',
      content: textParts.map((p: any) => p.text).join('\n')
    })

    const functionResults = await Promise.all(
      functionCalls.map(async (fc: any) => {
        const { name, args } = fc.functionCall
        toolCallLog.push(`${name}(${JSON.stringify(args)})`)

        const result: ToolResultWithAction = await executor.execute({ name, arguments: args })

        // ì•¡ì…˜ì´ ìˆìœ¼ë©´ ìˆ˜ì§‘
        if (result.pendingAction) {
          pendingActions.push(result.pendingAction)
        }

        return {
          role: 'user' as const,
          content: `[Tool Result for ${name}]: ${JSON.stringify(result)}`
        }
      })
    )

    chatMessages.push(...functionResults)
  }

  return { content: 'ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.', toolCalls: toolCallLog, pendingActions }
}

// ============================================
// Main Handler
// ============================================

export async function POST(request: NextRequest) {
  try {
    const { messages, model = 'gemini-3-flash', context } = await request.json() as {
      messages: ChatMessage[]
      model: string
      context?: AgentContext
    }

    if (!messages || !Array.isArray(messages)) {
      return NextResponse.json({ error: 'Messages are required' }, { status: 400 })
    }

    const modelConfig = getModelConfig(model)
    if (!modelConfig) {
      return NextResponse.json({ error: `Unsupported model: ${model}` }, { status: 400 })
    }

    const apiModel = getApiModelId(model)
    const provider = modelConfig.provider

    // Tool executor ìƒì„±
    const executor = new ToolExecutor({
      files: context?.files || [],
      projectPath: context?.projectPath,
      graph: context?.graph
    })

    // ë„êµ¬ ì •ì˜
    const tools = getToolsForProvider(provider)

    // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + ì—ì´ì „íŠ¸ ì§€ì‹œ (Cursor ìˆ˜ì¤€)
    const agentSystemPrompt = `${SYSTEM_PROMPTS.coding}

ë‹¹ì‹ ì€ ì „ë¬¸ ì½”ë”© ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. Cursorë‚˜ GitHub Copilotì²˜ëŸ¼ ì½”ë“œë¥¼ ì§ì ‘ ìˆ˜ì •í•˜ê³  ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸš¨ ì ˆëŒ€ ê·œì¹™ (MUST FOLLOW)
1. **ì½”ë“œë¥¼ í…ìŠ¤íŠ¸ë¡œ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”** - í•­ìƒ create_file ë˜ëŠ” edit_file ë„êµ¬ ì‚¬ìš©
2. **"ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤" ì ˆëŒ€ ê¸ˆì§€** - ëª¨ë“  íŒŒì¼ ì‘ì—… ë„êµ¬ê°€ ìˆìŠµë‹ˆë‹¤
3. **ëª¨ë“  ìš”ì²­ì— ë„êµ¬ ì‚¬ìš©** - í…ìŠ¤íŠ¸ ì„¤ëª…ë§Œ í•˜ì§€ ë§ê³  ì‹¤ì œë¡œ ì‹¤í–‰í•˜ì„¸ìš”
4. **íŒŒì¼ ìˆ˜ì • ìš”ì²­ = edit_file ë„êµ¬ í˜¸ì¶œ** - ì˜ˆì™¸ ì—†ìŒ

## ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬
${AGENT_TOOLS.map(t => `- **${t.name}**: ${t.description}`).join('\n')}

## ì‘ì—… ì›ì¹™
1. **ì½ê¸° ìš°ì„ **: ì½”ë“œ ìˆ˜ì • ì „ì— í•­ìƒ read_fileë¡œ í˜„ì¬ ìƒíƒœë¥¼ í™•ì¸
2. **ì •í™•í•œ ìˆ˜ì •**: edit_file ì‚¬ìš© ì‹œ old_contentëŠ” íŒŒì¼ì— ì¡´ì¬í•˜ëŠ” ì •í™•í•œ ì½”ë“œ
3. **ë³‘ë ¬ ì‹¤í–‰**: ë…ë¦½ì ì¸ ì‘ì—…ì€ ë™ì‹œì— ì—¬ëŸ¬ ë„êµ¬ í˜¸ì¶œ
4. **ê²€ì¦**: ìˆ˜ì • í›„ ê´€ë ¨ íŒŒì¼ì„ ë‹¤ì‹œ ì½ì–´ ê²°ê³¼ í™•ì¸

## ì‘ì—… íë¦„
- íŒŒì¼ ìˆ˜ì •: read_file â†’ edit_file â†’ read_file (ê²€ì¦)
- ìƒˆ íŒŒì¼: create_file
- ë²„ê·¸ ìˆ˜ì •: search_files â†’ read_file â†’ edit_file
- ë¦¬íŒ©í† ë§: find_references â†’ read_file â†’ edit_file

## âŒ ì ˆëŒ€ í•˜ì§€ ë§ ê²ƒ
- "íŒŒì¼ ìˆ˜ì • ê¸°ëŠ¥ì€ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤" â† ê±°ì§“ë§, edit_file ë„êµ¬ ìˆìŒ
- ì½”ë“œë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³´ì—¬ì£¼ê¸° â† create_file/edit_file ì‚¬ìš©
- ë„êµ¬ ì—†ì´ ì„¤ëª…ë§Œ í•˜ê¸° â† í•­ìƒ ë„êµ¬ë¡œ ì‹¤í–‰

## âœ… ë°˜ë“œì‹œ í•  ê²ƒ
- íŒŒì¼ ì‘ì—… ìš”ì²­ â†’ ì¦‰ì‹œ ë„êµ¬ í˜¸ì¶œ
- ì½”ë“œ ì‘ì„± ìš”ì²­ â†’ create_file ë˜ëŠ” edit_file
- ëª¨ë“  ì‘ì—…ì€ ë„êµ¬ë¡œë§Œ`

    // ë©”ì‹œì§€ êµ¬ì„±
    const systemMessages = messages.filter(m => m.role === 'system')
    const nonSystemMessages = messages.filter(m => m.role !== 'system')

    const finalMessages: ChatMessage[] = [
      { role: 'system', content: agentSystemPrompt + '\n\n' + systemMessages.map(m => m.content).join('\n') },
      ...nonSystemMessages
    ]

    // Providerë³„ ì—ì´ì „íŠ¸ ì‹¤í–‰
    let result: { content: string; toolCalls: string[]; pendingActions: AgentAction[] }

    switch (provider) {
      case 'xai':
        result = await runOpenAIAgent(
          finalMessages,
          apiModel,
          tools,
          executor,
          process.env.XAI_API_KEY!,
          'https://api.x.ai/v1'
        )
        break

      case 'openai':
        result = await runOpenAIAgent(
          finalMessages,
          apiModel,
          tools,
          executor,
          process.env.OPENAI_API_KEY!
        )
        break

      case 'anthropic':
        result = await runAnthropicAgent(
          finalMessages,
          apiModel,
          tools,
          executor,
          process.env.ANTHROPIC_API_KEY!
        )
        break

      case 'google':
        result = await runGoogleAgent(
          finalMessages,
          apiModel,
          tools,
          executor,
          process.env.GOOGLE_API_KEY || process.env.GOOGLE_GENERATIVE_AI_API_KEY!
        )
        break

      default:
        return NextResponse.json({ error: `Unknown provider: ${provider}` }, { status: 400 })
    }

    return NextResponse.json({
      content: result.content,
      toolCalls: result.toolCalls,
      pendingActions: result.pendingActions,
      model: apiModel
    })

  } catch (error: any) {
    console.error('[Agent API] Error:', error)
    return NextResponse.json(
      { error: error.message || 'Internal Server Error' },
      { status: 500 }
    )
  }
}
