"use client"

import { useState, useRef, useEffect, useCallback } from "react"
import { motion, AnimatePresence } from "framer-motion"
import { X, Bell, AlertTriangle, CheckCircle, Sparkles, Send, Loader2, Mic, Volume2, VolumeX } from "lucide-react"
import { useAgentNotification, AgentNotification } from "@/lib/contexts/AgentNotificationContext"
import { useThemeStore, accentColors } from "@/stores/themeStore"
import { executeActions, convertToolAction, formatActionResultsForChat } from "@/lib/ai/agent-actions"

// ì—¬ì„± ì—ì´ì „íŠ¸ ì´ë¦„ ëª©ë¡
const FEMALE_AGENTS = ['ì—ì´ë¯¸', 'amy', 'ë ˆì´ì²¼', 'rachel', 'ì• ë‹ˆ', 'ani', 'ì†Œí”¼ì•„', 'sophia']

// Web Speech API íƒ€ì…
interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList
  resultIndex: number
}

interface SpeechRecognitionResultList {
  length: number
  item(index: number): SpeechRecognitionResult
  [index: number]: SpeechRecognitionResult
}

interface SpeechRecognitionResult {
  isFinal: boolean
  length: number
  item(index: number): SpeechRecognitionAlternative
  [index: number]: SpeechRecognitionAlternative
}

interface SpeechRecognitionAlternative {
  transcript: string
  confidence: number
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean
  interimResults: boolean
  lang: string
  maxAlternatives?: number
  start(): void
  stop(): void
  abort(): void
  onresult: ((event: SpeechRecognitionEvent) => void) | null
  onerror: ((event: Event) => void) | null
  onend: (() => void) | null
  onstart: (() => void) | null
  onaudiostart: (() => void) | null
  onaudioend: (() => void) | null
  onspeechstart: (() => void) | null
  onspeechend: (() => void) | null
  onsoundstart: (() => void) | null
  onsoundend: (() => void) | null
}

declare global {
  interface Window {
    SpeechRecognition: new () => SpeechRecognition
    webkitSpeechRecognition: new () => SpeechRecognition
  }
}

const typeIcons = {
  info: Bell,
  alert: AlertTriangle,
  task: CheckCircle,
  greeting: Sparkles,
}

function NotificationItem({ notification, index }: { notification: AgentNotification; index: number }) {
  const { dismissNotification, showAgentNotification, isVoiceCallActive } = useAgentNotification()
  const { accentColor: themeAccent } = useThemeStore()
  const { agent, message, type, emotion } = notification

  // ì±„íŒ… ìƒíƒœ - íŒì—… ëœ¨ë©´ ë°”ë¡œ ë‹µì¥ ëª¨ë“œ
  const [showReply, setShowReply] = useState(true)
  const [replyText, setReplyText] = useState("")
  const [isProcessing, setIsProcessing] = useState(false)
  const [agentResponse, setAgentResponse] = useState<string | null>(null)

  // ìŒì„± ì¸ì‹ ìƒíƒœ (STT - Whisper API)
  const [isListening, setIsListening] = useState(false)
  const isListeningRef = useRef(false)
  const mediaStreamRef = useRef<MediaStream | null>(null)

  // TTS ìƒíƒœ
  const [isSpeaking, setIsSpeaking] = useState(false)
  const [speakingText, setSpeakingText] = useState("") // ì‹¤ì‹œê°„ ë§í•˜ëŠ” í…ìŠ¤íŠ¸
  const [ttsMode, setTtsMode] = useState<"native" | "grok">("grok") // ê¸°ë³¸: AI ìŒì„± (Grok)
  const ttsPlayedRef = useRef(false) // refë¡œ ë³€ê²½í•˜ì—¬ ë¦¬ë Œë”ë§ ë°©ì§€
  const speakMessageRef = useRef<((text: string) => Promise<void>) | null>(null)
  const speechSynthRef = useRef<SpeechSynthesisUtterance | null>(null)
  const [micReady, setMicReady] = useState(false) // TTS ëë‚˜ë©´ ë§ˆì´í¬ ë²„íŠ¼ ê°•ì¡°
  const autoStartSTTRef = useRef(true) // TTS ëë‚˜ë©´ ìë™ STT ì‹œì‘
  const startRecognitionRef = useRef<(() => void) | null>(null)
  const currentAudioRef = useRef<HTMLAudioElement | null>(null)

  // í…Œë§ˆ ìƒ‰ìƒ
  const themeColorData = accentColors.find(c => c.id === themeAccent)
  const themeColor = themeColorData?.color || "#3b82f6"

  // ì•„ë°”íƒ€ URL
  const getDefaultAvatarUrl = () => {
    const nameLower = agent.name.toLowerCase()
    const isFemale = FEMALE_AGENTS.some(n => nameLower.includes(n))
    const seed = isFemale ? `${agent.name}-female` : agent.name
    return `https://api.dicebear.com/7.x/lorelei/svg?seed=${encodeURIComponent(seed)}`
  }

  const avatarUrl = emotion && agent.emotion_avatars?.[emotion]
    ? agent.emotion_avatars[emotion]
    : agent.avatar_url || getDefaultAvatarUrl()

  const Icon = typeIcons[type]

  // ========== TTS: ë©”ì‹œì§€ ìŒì„± ì¬ìƒ ==========

  // ë¸Œë¼ìš°ì € ë„¤ì´í‹°ë¸Œ TTS (ì•ˆì •ì , ëŠê¸°ì§€ ì•ŠìŒ)
  const speakNative = useCallback((text: string) => {
    if (!window.speechSynthesis) {
      console.error("[TTS Native] Speech synthesis not supported")
      return
    }

    // ì´ì „ ë°œí™” ì·¨ì†Œ
    window.speechSynthesis.cancel()

    const utterance = new SpeechSynthesisUtterance(text)
    utterance.lang = "ko-KR"
    utterance.rate = 0.95
    utterance.pitch = 1.1

    // í•œêµ­ì–´ ìŒì„± ì°¾ê¸°
    const voices = window.speechSynthesis.getVoices()
    const koreanVoice = voices.find(v => v.lang.startsWith("ko"))
    if (koreanVoice) {
      utterance.voice = koreanVoice
    }

    // ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ í‘œì‹œë¥¼ ìœ„í•œ ë‹¨ì–´ ë‹¨ìœ„ ì—…ë°ì´íŠ¸
    let currentIndex = 0
    const words = text.split("")
    const intervalId = setInterval(() => {
      if (currentIndex < words.length) {
        setSpeakingText(prev => prev + words[currentIndex])
        currentIndex++
      } else {
        clearInterval(intervalId)
      }
    }, 80) // ê¸€ìë‹¹ 80ms

    utterance.onend = () => {
      console.log("[TTS Native] Speech ended")
      clearInterval(intervalId)
      setSpeakingText(text)
      setIsSpeaking(false)
      // TTS ëë‚˜ë©´ ìë™ìœ¼ë¡œ ë§ˆì´í¬ ì‹œì‘
      if (autoStartSTTRef.current && startRecognitionRef.current) {
        console.log("[TTS->STT] Auto-starting STT...")
        setMicReady(true)
        isListeningRef.current = true
        setIsListening(true)
        setTimeout(() => startRecognitionRef.current?.(), 100)
      }
    }

    utterance.onerror = (e) => {
      console.error("[TTS Native] Error:", e)
      clearInterval(intervalId)
      setIsSpeaking(false)
      setSpeakingText("")
    }

    speechSynthRef.current = utterance
    window.speechSynthesis.speak(utterance)
    console.log("[TTS Native] Speaking:", text)
  }, [])

  // ğŸ”¥ Grok TTS (REST API - ì•ˆì •ì )
  const speakGrok = useCallback(async (text: string) => {
    console.log("[TTS Grok] ğŸš€ Starting with REST API for:", text.substring(0, 30) + "...")

    try {
      const voiceSettings = agent.voice_settings || {}
      const selectedVoice = voiceSettings.voice || "tara"

      console.log(`[TTS Grok] ğŸ™ï¸ Using voice: ${selectedVoice}, agent:`, agent.name)

      // ğŸ”¥ REST API ì‚¬ìš© (WebSocketë³´ë‹¤ ì•ˆì •ì )
      console.log("[TTS Grok] ğŸ“¡ Calling /api/voice/grok...")
      const response = await fetch("/api/voice/grok", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ text, voice: selectedVoice }),
      })

      console.log("[TTS Grok] ğŸ“¥ Response status:", response.status)

      if (!response.ok) {
        const errorText = await response.text()
        console.error("[TTS Grok] âŒ API Error:", errorText)
        throw new Error(`TTS API failed: ${response.status} - ${errorText}`)
      }

      // ì˜¤ë””ì˜¤ ì¬ìƒ
      const audioBlob = await response.blob()
      const audioUrl = URL.createObjectURL(audioBlob)
      const audio = new Audio(audioUrl)
      currentAudioRef.current = audio

      // ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ í‘œì‹œ
      let currentIndex = 0
      const chars = text.split("")
      const intervalId = setInterval(() => {
        if (currentIndex < chars.length) {
          setSpeakingText(prev => prev + chars[currentIndex])
          currentIndex++
        } else {
          clearInterval(intervalId)
        }
      }, 50)

      audio.onended = () => {
        console.log("[TTS Grok] Audio playback ended")
        clearInterval(intervalId)
        setSpeakingText(text)
        URL.revokeObjectURL(audioUrl)
        setIsSpeaking(false)

        // TTS ëë‚˜ë©´ ìë™ìœ¼ë¡œ ë§ˆì´í¬ ì‹œì‘
        if (autoStartSTTRef.current && startRecognitionRef.current) {
          console.log("[TTS->STT] Auto-starting STT...")
          setMicReady(true)
          isListeningRef.current = true
          setIsListening(true)
          setTimeout(() => startRecognitionRef.current?.(), 100)
        }
      }

      audio.onerror = () => {
        console.error("[TTS Grok] Audio playback error")
        clearInterval(intervalId)
        URL.revokeObjectURL(audioUrl)
        setIsSpeaking(false)
        setSpeakingText("")
      }

      await audio.play()
      console.log("[TTS Grok] Audio playing...")

    } catch (error) {
      console.error("[TTS Grok] Error:", error)
      setIsSpeaking(false)
      setSpeakingText("")
      // ğŸ”¥ Grok ì‹¤íŒ¨ ì‹œ ë„¤ì´í‹°ë¸Œ TTSë¡œ í´ë°±
      console.log("[TTS] Falling back to native TTS...")
      speakNative(text)
    }
  }, [agent.voice_settings, speakNative])

  // ì´ëª¨ì§€ ì œê±° í•¨ìˆ˜
  const removeEmojis = (text: string): string => {
    return text
      .replace(/[\u{1F600}-\u{1F64F}]/gu, '') // ì´ëª¨í‹°ì½˜
      .replace(/[\u{1F300}-\u{1F5FF}]/gu, '') // ê¸°í˜¸ ë° í”½í† ê·¸ë¨
      .replace(/[\u{1F680}-\u{1F6FF}]/gu, '') // êµí†µ ë° ì§€ë„
      .replace(/[\u{1F1E0}-\u{1F1FF}]/gu, '') // êµ­ê¸°
      .replace(/[\u{2600}-\u{26FF}]/gu, '')   // ê¸°íƒ€ ê¸°í˜¸
      .replace(/[\u{2700}-\u{27BF}]/gu, '')   // ë”©ë±ƒ
      .replace(/[\u{FE00}-\u{FE0F}]/gu, '')   // ë³€í˜• ì„ íƒì
      .replace(/[\u{1F900}-\u{1F9FF}]/gu, '') // ë³´ì¶© ê¸°í˜¸
      .replace(/[\u{1FA00}-\u{1FA6F}]/gu, '') // ì²´ìŠ¤ ê¸°í˜¸
      .replace(/[\u{1FA70}-\u{1FAFF}]/gu, '') // ê¸°í˜¸ í™•ì¥
      .replace(/[\u{231A}-\u{231B}]/gu, '')   // ì‹œê³„
      .replace(/[\u{23E9}-\u{23F3}]/gu, '')   // ë¯¸ë””ì–´
      .replace(/[\u{23F8}-\u{23FA}]/gu, '')   // ë¯¸ë””ì–´
      .replace(/[\u{25AA}-\u{25AB}]/gu, '')   // ë„í˜•
      .replace(/[\u{25B6}]/gu, '')
      .replace(/[\u{25C0}]/gu, '')
      .replace(/[\u{25FB}-\u{25FE}]/gu, '')
      .replace(/[\u{2614}-\u{2615}]/gu, '')
      .replace(/[\u{2648}-\u{2653}]/gu, '')
      .replace(/[\u{267F}]/gu, '')
      .replace(/[\u{2693}]/gu, '')
      .replace(/[\u{26A1}]/gu, '')
      .replace(/[\u{26AA}-\u{26AB}]/gu, '')
      .replace(/[\u{26BD}-\u{26BE}]/gu, '')
      .replace(/[\u{26C4}-\u{26C5}]/gu, '')
      .replace(/[\u{26CE}]/gu, '')
      .replace(/[\u{26D4}]/gu, '')
      .replace(/[\u{26EA}]/gu, '')
      .replace(/[\u{26F2}-\u{26F3}]/gu, '')
      .replace(/[\u{26F5}]/gu, '')
      .replace(/[\u{26FA}]/gu, '')
      .replace(/[\u{26FD}]/gu, '')
      .replace(/\s+/g, ' ')  // ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
      .trim()
  }

  // TTSë¡œ ë©”ì‹œì§€ ì½ê¸° (ëª¨ë“œì— ë”°ë¼ ë¶„ê¸°)
  const speakMessage = useCallback(async (text: string) => {
    console.log("[TTS] ğŸ¯ speakMessage called! isVoiceCallActive:", isVoiceCallActive, "isSpeaking:", isSpeaking, "ttsMode:", ttsMode)

    // ğŸ”¥ ìŒì„±í†µí™” ì¤‘ì´ë©´ ì•Œë¦¼ TTS ë¹„í™œì„±í™” (ì¤‘ë³µ ìŒì„± ë°©ì§€)
    if (isVoiceCallActive) {
      console.log("[TTS] âš ï¸ Voice call active, skipping notification TTS")
      return
    }

    // ì´ëª¨ì§€ ì œê±°
    const cleanText = removeEmojis(text)
    console.log("[TTS] ğŸ“ Clean text:", cleanText.substring(0, 50) + "...")

    if (isSpeaking) {
      console.log("[TTS] Already speaking, skipping")
      return
    }

    if (!cleanText) {
      console.log("[TTS] No text to speak after emoji removal")
      return
    }

    setIsSpeaking(true)
    setSpeakingText("")

    if (ttsMode === "native") {
      speakNative(cleanText)
    } else {
      await speakGrok(cleanText)
    }
  }, [isSpeaking, ttsMode, speakNative, speakGrok, isVoiceCallActive])

  // speakMessageë¥¼ refì— ì €ì¥ (ì¦‰ì‹œ + useEffectë¡œ ì—…ë°ì´íŠ¸)
  // ğŸ”¥ ì¦‰ì‹œ í• ë‹¹í•˜ì—¬ ì´ˆê¸° ë§ˆìš´íŠ¸ ì‹œì—ë„ refê°€ ì„¤ì •ë˜ë„ë¡ í•¨
  speakMessageRef.current = speakMessage

  useEffect(() => {
    speakMessageRef.current = speakMessage
    console.log("[TTS] speakMessageRef updated")
  }, [speakMessage])

  // íŒì—…ì´ ì—´ë¦¬ë©´ ìë™ìœ¼ë¡œ TTS ì¬ìƒ (í•œ ë²ˆë§Œ ì‹¤í–‰)
  useEffect(() => {
    if (!ttsPlayedRef.current && message) {
      ttsPlayedRef.current = true
      console.log("[TTS] ğŸ”Š Auto-triggering TTS for message:", message)

      // ğŸ”¥ refë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì‹  speakMessage í˜¸ì¶œ (ì˜ì¡´ì„± ë³€ê²½ìœ¼ë¡œ ì¸í•œ íƒ€ì´ë¨¸ ì·¨ì†Œ ë°©ì§€)
      const timer = setTimeout(() => {
        console.log("[TTS] ğŸ¤ Calling speakMessage now via ref...")
        if (speakMessageRef.current) {
          speakMessageRef.current(message)
        } else {
          console.error("[TTS] âŒ speakMessageRef.current is null!")
        }
      }, 300) // 300msë¡œ ë‹¨ì¶• (ë¹ ë¥¸ ì‘ë‹µ)

      return () => clearTimeout(timer)
    }
  }, [message]) // speakMessage ì œê±°í•˜ì—¬ íƒ€ì´ë¨¸ ì·¨ì†Œ ë°©ì§€

  // ì •ë¦¬
  useEffect(() => {
    return () => {
      // í˜„ì¬ ì¬ìƒ ì¤‘ì¸ ì˜¤ë””ì˜¤ ì¤‘ì§€
      if (currentAudioRef.current) {
        currentAudioRef.current.pause()
        currentAudioRef.current = null
      }
      // ë„¤ì´í‹°ë¸Œ TTSë„ ì·¨ì†Œ
      if (typeof window !== "undefined" && window.speechSynthesis) {
        window.speechSynthesis.cancel()
      }
    }
  }, [])

  // ========== STT: MediaRecorder + Whisper API ==========
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const audioChunksRef = useRef<Blob[]>([])

  // ë…¹ìŒ ì‹œì‘
  const startRecognition = useCallback(async () => {
    console.log("[STT] Starting...")

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
      mediaStreamRef.current = stream
      console.log("[STT] Mic OK")

      // mimeType í˜¸í™˜ì„± í™•ì¸
      let mimeType = 'audio/webm'
      if (!MediaRecorder.isTypeSupported('audio/webm')) {
        mimeType = 'audio/mp4'
        if (!MediaRecorder.isTypeSupported('audio/mp4')) {
          mimeType = 'audio/ogg'
          if (!MediaRecorder.isTypeSupported('audio/ogg')) {
            mimeType = '' // ê¸°ë³¸ê°’ ì‚¬ìš©
          }
        }
      }
      console.log("[STT] Using mimeType:", mimeType || "default")

      const mediaRecorder = mimeType
        ? new MediaRecorder(stream, { mimeType })
        : new MediaRecorder(stream)
      mediaRecorderRef.current = mediaRecorder
      audioChunksRef.current = []

      mediaRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) {
          audioChunksRef.current.push(e.data)
        }
      }

      mediaRecorder.onstop = async () => {
        console.log("[STT] Sending to Whisper...")

        const audioBlob = new Blob(audioChunksRef.current, { type: mediaRecorder.mimeType || 'audio/webm' })

        if (audioBlob.size < 1000) {
          console.log("[STT] Audio too short")
          return
        }

        try {
          const baseType = audioBlob.type.split(';')[0]
          let ext = 'webm'
          if (baseType.includes('webm')) ext = 'webm'
          else if (baseType.includes('mp4') || baseType.includes('m4a')) ext = 'm4a'
          else if (baseType.includes('ogg')) ext = 'ogg'
          else if (baseType.includes('mpeg') || baseType.includes('mp3')) ext = 'mp3'
          else if (baseType.includes('wav')) ext = 'wav'

          const formData = new FormData()
          formData.append('audio', audioBlob, `audio.${ext}`)

          const res = await fetch('/api/voice/stt', {
            method: 'POST',
            body: formData,
          })

          if (res.ok) {
            const data = await res.json()
            if (data.text) {
              console.log("[STT] âœ…", data.text)
              setReplyText(prev => prev + data.text)
            }
          } else {
            console.error("[STT] API error:", await res.text())
          }
        } catch (err) {
          console.error("[STT] Error:", err)
        }
      }

      mediaRecorder.start(1000)
      console.log("[STT] Recording...")

    } catch (error: any) {
      console.error("[STT] Error:", error)
      isListeningRef.current = false
      setIsListening(false)
    }
  }, [])

  // ë…¹ìŒ ì¤‘ì§€ ë° ë³€í™˜
  const stopRecognition = useCallback(() => {
    console.log("[STT] Stopping...")
    isListeningRef.current = false

    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
      mediaRecorderRef.current.stop()
    }

    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => track.stop())
      mediaStreamRef.current = null
    }

    setIsListening(false)
  }, [])

  // startRecognitionì„ refì— ì €ì¥ (TTS ì™„ë£Œ í›„ í˜¸ì¶œìš©)
  useEffect(() => {
    startRecognitionRef.current = startRecognition
  }, [startRecognition])

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useEffect(() => {
    return () => {
      stopRecognition()
    }
  }, [stopRecognition])

  // ìŒì„± ì¸ì‹ í† ê¸€
  const toggleListening = async () => {
    console.log("[STT Toggle] Current state:", { isListening })

    if (isListening) {
      console.log("[STT Toggle] Stopping...")
      stopRecognition()
    } else {
      console.log("[STT Toggle] Starting Grok STT...")
      isListeningRef.current = true
      setIsListening(true)
      await startRecognition()
    }
  }

  // ========== ë‹µì¥ ì „ì†¡ ==========
  const handleSendReply = async () => {
    if (!replyText.trim() || isProcessing) return

    setIsProcessing(true)
    try {
      const response = await fetch(`/api/agents/${agent.id}/chat`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          message: replyText,
          context: `ì‚¬ìš©ìê°€ "${message}"ì— ëŒ€í•´ ë‹µì¥í–ˆìŠµë‹ˆë‹¤.`,
        }),
      })

      if (response.ok) {
        const data = await response.json()
        const agentReply = data.response || data.message || "ì•Œê² ìŠµë‹ˆë‹¤."

        // ğŸ”¥ ì—ì´ì „íŠ¸ê°€ ë°˜í™˜í•œ ì•¡ì…˜ë“¤ ì‹¤í–‰ (í”„ë¡œì íŠ¸ ìƒì„±, íŒŒì¼ ì‘ì„± ë“±)
        if (data.actions && data.actions.length > 0) {
          console.log("[AgentChat] ğŸš€ Executing agent actions:", data.actions)
          try {
            // ToolAction â†’ AgentAction ë³€í™˜ í›„ ì‹¤í–‰
            const agentActions = data.actions
              .map((action: any) => convertToolAction(action))
              .filter((a: any) => a !== null)

            if (agentActions.length > 0) {
              const results = await executeActions(agentActions)
              const actionSummary = formatActionResultsForChat(results)

              // ì‹¤í–‰ ê²°ê³¼ë¥¼ ì‘ë‹µì— ì¶”ê°€
              if (actionSummary) {
                setAgentResponse(`${agentReply}\n\nğŸ“‹ ì‹¤í–‰ ê²°ê³¼:\n${actionSummary}`)
              } else {
                setAgentResponse(agentReply)
              }

              console.log("[AgentChat] âœ… Actions executed:", results)
            } else {
              setAgentResponse(agentReply)
            }
          } catch (actionError) {
            console.error("[AgentChat] âŒ Action execution failed:", actionError)
            setAgentResponse(`${agentReply}\n\nâš ï¸ ì¼ë¶€ ì‘ì—… ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.`)
          }
        } else {
          setAgentResponse(agentReply)
        }

        setReplyText("")

        // ì—ì´ì „íŠ¸ ì‘ë‹µë„ TTSë¡œ ì½ê¸°
        setTimeout(() => {
          speakMessage(agentReply)
        }, 300)
      } else {
        setAgentResponse("ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
      }
    } catch (error) {
      console.error("Reply error:", error)
      setAgentResponse("ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    } finally {
      setIsProcessing(false)
    }
  }

  return (
    <motion.div
      initial={{ opacity: 0 }}
      animate={{ opacity: 1 }}
      exit={{ opacity: 0 }}
      className="fixed inset-0 bg-black/60 backdrop-blur-sm flex items-center justify-center"
      onClick={() => dismissNotification(notification.id)}
      style={{ zIndex: 100 + index }}
    >
      {/* íŒì—… ì¹´ë“œ */}
      <motion.div
        initial={{ opacity: 0, scale: 0.8, y: 20 }}
        animate={{ opacity: 1, scale: 1, y: 0 }}
        exit={{ opacity: 0, scale: 0.8, y: 20 }}
        transition={{ type: "spring", damping: 25, stiffness: 400 }}
        className="w-[380px]"
        onClick={(e) => e.stopPropagation()}
      >
        <div
          className="relative bg-gradient-to-b from-zinc-900 to-zinc-950 rounded-3xl overflow-hidden"
          style={{
            boxShadow: `0 0 80px ${themeColor}30, 0 0 120px ${themeColor}10, 0 25px 50px -12px rgba(0, 0, 0, 0.8)`,
          }}
        >
          {/* ìƒë‹¨ ê¸€ë¡œìš° íš¨ê³¼ */}
          <div
            className="absolute top-0 left-1/2 -translate-x-1/2 w-40 h-40 rounded-full blur-3xl opacity-30"
            style={{ background: themeColor }}
          />

          {/* ë‹«ê¸° ë²„íŠ¼ */}
          <button
            onClick={() => dismissNotification(notification.id)}
            className="absolute top-4 right-4 p-2 rounded-full bg-zinc-800/50 hover:bg-zinc-700/50 transition-all z-20 group"
          >
            <X className="w-4 h-4 text-zinc-500 group-hover:text-zinc-300" />
          </button>

          {/* ìŒì„± ìƒíƒœ í‘œì‹œ */}
          {isSpeaking && (
            <div className="absolute top-4 left-4 flex items-center gap-2 px-3 py-1.5 rounded-full bg-zinc-800/80 z-20">
              <motion.div
                animate={{ scale: [1, 1.2, 1] }}
                transition={{ repeat: Infinity, duration: 0.8 }}
                className="w-2 h-2 rounded-full"
                style={{ backgroundColor: themeColor }}
              />
              <span className="text-xs text-zinc-400">ë§í•˜ëŠ” ì¤‘...</span>
            </div>
          )}

          {/* í”„ë¡œí•„ ì„¹ì…˜ */}
          <div className="relative pt-8 pb-4 flex flex-col items-center">
            <div className="relative">
              <motion.div
                animate={{ rotate: 360 }}
                transition={{ duration: 8, repeat: Infinity, ease: "linear" }}
                className="absolute -inset-2 rounded-full"
                style={{
                  background: `conic-gradient(from 0deg, ${themeColor}, transparent, ${themeColor})`,
                  opacity: 0.5,
                }}
              />
              <motion.div
                initial={{ scale: 0, rotate: -180 }}
                animate={{ scale: 1, rotate: 0 }}
                transition={{ type: "spring", damping: 15, stiffness: 200, delay: 0.1 }}
                className="relative w-24 h-24 rounded-full p-1"
                style={{
                  background: `linear-gradient(135deg, ${themeColor}, ${themeColor}60)`,
                }}
              >
                <div className="w-full h-full rounded-full overflow-hidden bg-zinc-900">
                  <img
                    src={avatarUrl}
                    alt={agent.name}
                    className="w-full h-full object-cover"
                  />
                </div>
              </motion.div>
              <motion.div
                initial={{ scale: 0 }}
                animate={{ scale: 1 }}
                transition={{ delay: 0.3, type: "spring" }}
                className="absolute -bottom-1 -right-1 w-8 h-8 rounded-full flex items-center justify-center border-2 border-zinc-900"
                style={{ backgroundColor: themeColor }}
              >
                <Icon className="w-4 h-4 text-white" />
              </motion.div>
            </div>

            <motion.div
              initial={{ opacity: 0, y: 10 }}
              animate={{ opacity: 1, y: 0 }}
              transition={{ delay: 0.2 }}
              className="mt-4 text-center"
            >
              <h3 className="text-xl font-bold" style={{ color: themeColor }}>
                {agent.name}
              </h3>
              <p className="text-xs text-zinc-500 mt-0.5">
                {type === "greeting" ? "ì¸ì‚¬" : type === "alert" ? "ì•Œë¦¼" : type === "task" ? "íƒœìŠ¤í¬" : "ì •ë³´"}
              </p>
            </motion.div>
          </div>

          {/* ë©”ì‹œì§€ ì„¹ì…˜ */}
          <motion.div
            initial={{ opacity: 0, y: 10 }}
            animate={{ opacity: 1, y: 0 }}
            transition={{ delay: 0.3 }}
            className="px-6 pb-4"
          >
            <div className="bg-zinc-800/50 rounded-2xl p-4 border border-zinc-700/50">
              {/* ìŒì„± ì¬ìƒ ë²„íŠ¼ + íŒŒí˜• */}
              <div className="flex items-center justify-center gap-3 mb-3">
                {isSpeaking ? (
                  // ë§í•˜ëŠ” ì¤‘: íŒŒí˜• ì• ë‹ˆë©”ì´ì…˜
                  <div className="flex items-center gap-2">
                    <div className="flex items-center gap-1">
                      {[...Array(5)].map((_, i) => (
                        <motion.div
                          key={i}
                          animate={{ height: [4, 16, 4] }}
                          transition={{ repeat: Infinity, duration: 0.6, delay: i * 0.1 }}
                          className="w-1 rounded-full"
                          style={{ backgroundColor: themeColor }}
                        />
                      ))}
                    </div>
                    <button
                      onClick={() => {
                        if (currentAudioRef.current) {
                          currentAudioRef.current.pause()
                          currentAudioRef.current = null
                        }
                        if (window.speechSynthesis) window.speechSynthesis.cancel()
                        setIsSpeaking(false)
                        setSpeakingText("")
                      }}
                      className="p-2 rounded-full bg-zinc-700/50 hover:bg-zinc-600/50 transition-colors"
                    >
                      <VolumeX className="w-4 h-4 text-zinc-300" />
                    </button>
                  </div>
                ) : (
                  // ìŒì„± ì¬ìƒ ë²„íŠ¼ + ëª¨ë“œ í† ê¸€
                  <div className="flex items-center gap-2">
                    <button
                      onClick={() => {
                        console.log("[TTS] Manual trigger for message:", message)
                        speakMessage(message)
                      }}
                      className="flex items-center gap-2 px-4 py-2 rounded-full transition-all hover:scale-105"
                      style={{
                        background: `linear-gradient(135deg, ${themeColor}30, ${themeColor}10)`,
                        border: `1px solid ${themeColor}50`,
                      }}
                    >
                      <Volume2 className="w-4 h-4" style={{ color: themeColor }} />
                      <span className="text-xs font-medium" style={{ color: themeColor }}>
                        ìŒì„±ìœ¼ë¡œ ë“£ê¸°
                      </span>
                    </button>
                    {/* TTS ëª¨ë“œ í† ê¸€ */}
                    <button
                      onClick={() => setTtsMode(prev => prev === "native" ? "grok" : "native")}
                      className="px-2 py-1 rounded-full text-[10px] transition-all"
                      style={{
                        background: ttsMode === "grok" ? `${themeColor}30` : "rgba(100,100,100,0.3)",
                        border: `1px solid ${ttsMode === "grok" ? themeColor : "rgba(100,100,100,0.5)"}`,
                        color: ttsMode === "grok" ? themeColor : "#888",
                      }}
                      title={ttsMode === "native" ? "ê¸°ë³¸ ìŒì„± (ì•ˆì •ì )" : "AI ìŒì„± (ìì—°ìŠ¤ëŸ¬ì›€)"}
                    >
                      {ttsMode === "native" ? "ê¸°ë³¸" : "AI"}
                    </button>
                  </div>
                )}
              </div>

              {/* ë©”ì‹œì§€ í…ìŠ¤íŠ¸ - ë§í•˜ëŠ” ì¤‘ì´ë©´ ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ + ì›ë³¸ í‘œì‹œ */}
              {isSpeaking ? (
                <div className="space-y-2">
                  {/* ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ (ìˆìœ¼ë©´ í‘œì‹œ) */}
                  {speakingText && (
                    <p className="text-sm leading-relaxed text-center font-medium" style={{ color: themeColor }}>
                      {speakingText}
                    </p>
                  )}
                  {/* ì›ë³¸ ë©”ì‹œì§€ëŠ” í•­ìƒ í‘œì‹œ (ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ê°€ ì—†ì„ ë•Œ ë” ë°ê²Œ) */}
                  <p className={`text-sm leading-relaxed text-center ${speakingText ? "text-zinc-400" : "text-zinc-200"}`}>
                    {message}
                  </p>
                </div>
              ) : (
                <p className="text-sm text-zinc-200 leading-relaxed text-center">
                  {message}
                </p>
              )}
            </div>

            {/* ì—ì´ì „íŠ¸ ì‘ë‹µ */}
            <AnimatePresence>
              {agentResponse && (
                <motion.div
                  initial={{ opacity: 0, y: 10 }}
                  animate={{ opacity: 1, y: 0 }}
                  exit={{ opacity: 0 }}
                  className="mt-3 rounded-2xl p-4 border"
                  style={{
                    backgroundColor: `${themeColor}15`,
                    borderColor: `${themeColor}30`,
                  }}
                >
                  {/* ì‘ë‹µ ìŒì„± ì¬ìƒ ë²„íŠ¼ + íŒŒí˜• */}
                  <div className="flex items-center justify-center gap-2 mb-3">
                    {isSpeaking ? (
                      <div className="flex items-center gap-2">
                        <div className="flex items-center gap-1">
                          {[...Array(5)].map((_, i) => (
                            <motion.div
                              key={i}
                              animate={{ height: [4, 16, 4] }}
                              transition={{ repeat: Infinity, duration: 0.6, delay: i * 0.1 }}
                              className="w-1 rounded-full"
                              style={{ backgroundColor: themeColor }}
                            />
                          ))}
                        </div>
                        <button
                          onClick={() => {
                            if (currentAudioRef.current) {
                              currentAudioRef.current.pause()
                              currentAudioRef.current = null
                            }
                            if (window.speechSynthesis) window.speechSynthesis.cancel()
                            setIsSpeaking(false)
                            setSpeakingText("")
                          }}
                          className="p-1.5 rounded-full bg-zinc-700/50 hover:bg-zinc-600/50"
                        >
                          <VolumeX className="w-3 h-3 text-zinc-300" />
                        </button>
                      </div>
                    ) : (
                      <button
                        onClick={() => speakMessage(agentResponse || "")}
                        className="flex items-center gap-1.5 px-3 py-1.5 rounded-full transition-all hover:scale-105"
                        style={{
                          background: `${themeColor}20`,
                          border: `1px solid ${themeColor}40`,
                        }}
                      >
                        <Volume2 className="w-3 h-3" style={{ color: themeColor }} />
                        <span className="text-xs" style={{ color: themeColor }}>ë“£ê¸°</span>
                      </button>
                    )}
                  </div>
                  {/* ì‘ë‹µ í…ìŠ¤íŠ¸ - ë§í•˜ëŠ” ì¤‘ì´ë©´ ì‹¤ì‹œê°„ + ì›ë³¸ */}
                  {isSpeaking ? (
                    <div className="space-y-2">
                      {speakingText && (
                        <p className="text-sm leading-relaxed text-center font-medium text-white">
                          {speakingText}
                        </p>
                      )}
                      <p className={`text-sm leading-relaxed text-center ${speakingText ? "opacity-60" : ""}`} style={{ color: themeColor }}>
                        {agentResponse}
                      </p>
                    </div>
                  ) : (
                    <p className="text-sm leading-relaxed text-center" style={{ color: themeColor }}>
                      {agentResponse}
                    </p>
                  )}
                </motion.div>
              )}
            </AnimatePresence>
          </motion.div>

          {/* ë‹µì¥ ì…ë ¥ ì„¹ì…˜ */}
          {!showReply && !agentResponse && (
            <motion.div
              initial={{ opacity: 0, y: 10 }}
              animate={{ opacity: 1, y: 0 }}
              transition={{ delay: 0.4 }}
              className="px-6 pb-6"
            >
              <div className="flex gap-3">
                <button
                  onClick={() => dismissNotification(notification.id)}
                  className="flex-1 py-3 px-4 text-sm font-semibold rounded-xl text-white transition-all hover:scale-[1.02] active:scale-[0.98]"
                  style={{
                    background: `linear-gradient(135deg, ${themeColor}, ${themeColor}cc)`,
                    boxShadow: `0 4px 20px ${themeColor}40`,
                  }}
                >
                  í™•ì¸
                </button>
                <button
                  onClick={() => setShowReply(true)}
                  className="flex-1 py-3 px-4 text-sm font-semibold rounded-xl bg-zinc-800 text-zinc-300 hover:bg-zinc-700 hover:text-white transition-all"
                >
                  ë‹µì¥
                </button>
              </div>
            </motion.div>
          )}

          {/* ì±„íŒ… ì…ë ¥ */}
          {showReply && !agentResponse && (
            <motion.div
              initial={{ opacity: 0, height: 0 }}
              animate={{ opacity: 1, height: "auto" }}
              className="px-6 pb-6"
            >
              {/* ìŒì„± ì¸ì‹ ì¤‘ í‘œì‹œ */}
              {isListening && (
                <motion.div
                  initial={{ opacity: 0 }}
                  animate={{ opacity: 1 }}
                  className="mb-3 flex items-center justify-center gap-2 py-2"
                >
                  <motion.div
                    animate={{ scale: [1, 1.3, 1] }}
                    transition={{ repeat: Infinity, duration: 0.8 }}
                    className="w-3 h-3 rounded-full"
                    style={{ backgroundColor: themeColor }}
                  />
                  <span className="text-sm" style={{ color: themeColor }}>
                    ë§ì”€í•˜ì„¸ìš”...
                  </span>
                </motion.div>
              )}

              <div className="flex gap-2">
                {/* ë§ˆì´í¬ ë²„íŠ¼ (STT - Grok) */}
                <motion.button
                  onClick={() => {
                    setMicReady(false)
                    toggleListening()
                  }}
                    disabled={isProcessing}
                    animate={micReady && !isListening ? {
                      scale: [1, 1.1, 1],
                      boxShadow: [`0 0 0px ${themeColor}`, `0 0 25px ${themeColor}`, `0 0 0px ${themeColor}`]
                    } : {}}
                    transition={micReady && !isListening ? { repeat: Infinity, duration: 1 } : {}}
                    className={`px-4 py-3 rounded-xl transition-all hover:scale-[1.02] active:scale-[0.98] ${
                      isListening
                        ? "text-white"
                        : micReady
                          ? "text-white"
                          : "bg-zinc-800 text-zinc-400 hover:text-zinc-200"
                    }`}
                    style={isListening || micReady ? {
                      background: `linear-gradient(135deg, ${themeColor}, ${themeColor}cc)`,
                      boxShadow: isListening ? `0 0 20px ${themeColor}50` : undefined,
                    } : {}}
                  >
                    {isListening ? (
                      <motion.div
                        animate={{ scale: [1, 1.2, 1] }}
                        transition={{ repeat: Infinity, duration: 0.8 }}
                      >
                        <Mic className="w-5 h-5" />
                      </motion.div>
                    ) : (
                      <Mic className="w-5 h-5" />
                    )}
                </motion.button>

                {/* í…ìŠ¤íŠ¸ ì…ë ¥ */}
                <input
                  type="text"
                  value={replyText}
                  onChange={(e) => setReplyText(e.target.value)}
                  onKeyDown={(e) => e.key === "Enter" && handleSendReply()}
                  placeholder={isListening ? "ë§ì”€í•˜ì„¸ìš”..." : `${agent.name}ì—ê²Œ ë‹µì¥...`}
                  className="flex-1 px-4 py-3 bg-zinc-800 border border-zinc-700 rounded-xl text-sm text-zinc-200 placeholder-zinc-500 focus:outline-none focus:border-zinc-600"
                  autoFocus={!isListening}
                  disabled={isProcessing || isListening}
                />

                {/* ì „ì†¡ ë²„íŠ¼ */}
                <button
                  onClick={handleSendReply}
                  disabled={!replyText.trim() || isProcessing}
                  className="px-4 py-3 rounded-xl text-white transition-all hover:scale-[1.02] active:scale-[0.98] disabled:opacity-50 disabled:hover:scale-100"
                  style={{
                    background: `linear-gradient(135deg, ${themeColor}, ${themeColor}cc)`,
                  }}
                >
                  {isProcessing ? (
                    <Loader2 className="w-5 h-5 animate-spin" />
                  ) : (
                    <Send className="w-5 h-5" />
                  )}
                </button>
              </div>

              {/* ì·¨ì†Œ ë²„íŠ¼ */}
              <button
                onClick={() => {
                  setShowReply(false)
                  setReplyText("")
                  if (isListening) {
                    stopRecognition()
                  }
                }}
                className="w-full mt-3 py-2 text-sm text-zinc-500 hover:text-zinc-300 transition-colors"
              >
                ì·¨ì†Œ
              </button>
            </motion.div>
          )}

          {/* ì‘ë‹µ í›„ ë‹«ê¸° ë²„íŠ¼ */}
          {agentResponse && (
            <motion.div
              initial={{ opacity: 0, y: 10 }}
              animate={{ opacity: 1, y: 0 }}
              className="px-6 pb-6"
            >
              <button
                onClick={() => dismissNotification(notification.id)}
                className="w-full py-3 px-4 text-sm font-semibold rounded-xl text-white transition-all hover:scale-[1.02] active:scale-[0.98]"
                style={{
                  background: `linear-gradient(135deg, ${themeColor}, ${themeColor}cc)`,
                  boxShadow: `0 4px 20px ${themeColor}40`,
                }}
              >
                í™•ì¸
              </button>
            </motion.div>
          )}
        </div>
      </motion.div>
    </motion.div>
  )
}

export function AgentNotificationPopup() {
  const { notifications } = useAgentNotification()

  return (
    <AnimatePresence mode="wait">
      {notifications.length > 0 && (
        <NotificationItem
          key={notifications[notifications.length - 1].id}
          notification={notifications[notifications.length - 1]}
          index={0}
        />
      )}
    </AnimatePresence>
  )
}
